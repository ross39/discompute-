#!/usr/bin/env python3
"""
Discompute Mobile Client for iOS
Compatible with Pyto, a-Shell, and other Python iOS apps

This Python script implements the same UDP discovery protocol
as the Go version, allowing iOS devices to participate in the
discompute network.
"""

import socket
import json
import time
import threading
import platform
import subprocess
import sys
import uuid
from datetime import datetime

# Try to import numpy, fall back to built-in math if not available
try:
    import numpy as np
    HAS_NUMPY = True
except ImportError:
    print("âš ï¸  NumPy not available - AI tasks will use basic math fallbacks")
    HAS_NUMPY = False

# Always import math and random (needed for fallbacks)
import math
import random

# Try to import grpc for real distributed communication
try:
    import grpc
    import concurrent.futures
    HAS_GRPC = True
    print("âœ… gRPC available - real distributed training enabled")
except ImportError:
    print("âš ï¸  gRPC not available - using simulation mode")
    HAS_GRPC = False

# Try to import tinygrad for real neural network training
try:
    from tinygrad import Tensor, nn, dtypes, TinyJit
    from tinygrad.nn.state import get_state_dict, load_state_dict, get_parameters
    from tinygrad.nn.datasets import mnist
    from tinygrad.nn.optim import Adam, SGD
    HAS_TINYGRAD = True
    print("ðŸ§  Tinygrad available - real neural network training enabled")
except ImportError:
    print("âš ï¸  Tinygrad not available - using simulation mode")
    HAS_TINYGRAD = False
from dataclasses import dataclass
from typing import Dict, List, Optional, Any, Tuple

@dataclass
class ComputeTask:
    """Represents a compute task that can be distributed across devices"""
    task_id: str
    task_type: str  # "training", "inference", "matrix_multiply", etc.
    task_data: Dict[str, Any]
    metadata: Dict[str, str]
    required_capabilities: List[str]
    estimated_duration: int
    priority: int = 5
    max_devices: int = 4
    target_subtasks: int = 1

@dataclass  
class SubTask:
    """Represents a subtask that runs on a specific device"""
    subtask_id: str
    parent_task_id: str
    subtask_index: int
    subtask_data: Dict[str, Any]
    assigned_device_id: str = ""
    status: str = "pending"  # pending, assigned, running, completed, failed
    started_at: Optional[float] = None
    completed_at: Optional[float] = None
    result_data: Optional[Dict[str, Any]] = None
    error_message: Optional[str] = None

@dataclass
class DistributedTrainingJob:
    """Represents a distributed neural network training job"""
    job_id: str
    model_config: Dict[str, Any]  # Network architecture
    training_config: Dict[str, Any]  # Training hyperparameters
    master_device_id: str
    slave_devices: List[str]
    current_epoch: int = 0
    total_epochs: int = 10
    model_parameters: Optional[Dict[str, Any]] = None
    training_data: Optional[List[Any]] = None
    status: str = "initialized"  # initialized, training, completed, failed

@dataclass
class TrainingBatch:
    """Represents a training batch sent to a slave device"""
    batch_id: str
    job_id: str
    epoch: int
    batch_index: int
    data: List[Any]  # Training samples
    labels: List[Any]  # Training labels
    model_weights: Dict[str, Any]  # Current model parameters
    learning_rate: float = 0.01

class TaskExecutor:
    """Executes compute tasks on the local device"""
    
    def __init__(self, device_capabilities):
        self.device_capabilities = device_capabilities
        self.running_tasks: Dict[str, SubTask] = {}
        
    async def execute_subtask(self, subtask: SubTask) -> SubTask:
        """Execute a subtask and return the result"""
        print(f"ðŸ”„ Executing subtask {subtask.subtask_id} of type {subtask.subtask_data.get('type', 'unknown')}")
        
        subtask.status = "running"
        subtask.started_at = time.time()
        self.running_tasks[subtask.subtask_id] = subtask
        
        try:
            # Route to appropriate executor based on task type
            task_type = subtask.subtask_data.get("type", "unknown")
            
            if task_type == "matrix_multiply":
                result = await self._execute_matrix_multiply(subtask)
            elif task_type == "simple_ml_training":
                result = await self._execute_simple_training(subtask)
            elif task_type == "data_processing":
                result = await self._execute_data_processing(subtask)
            else:
                result = await self._execute_dummy_task(subtask)
                
            subtask.result_data = result
            subtask.status = "completed"
            print(f"âœ… Subtask {subtask.subtask_id} completed successfully")
            
        except Exception as e:
            subtask.error_message = str(e)
            subtask.status = "failed"
            print(f"âŒ Subtask {subtask.subtask_id} failed: {e}")
            
        finally:
            subtask.completed_at = time.time()
            self.running_tasks.pop(subtask.subtask_id, None)
            
        return subtask
    
    async def _execute_matrix_multiply(self, subtask: SubTask) -> Dict[str, Any]:
        """Execute matrix multiplication task"""
        data = subtask.subtask_data
        
        # Simulate matrix multiplication work
        size = data.get("matrix_size", 100)
        iterations = data.get("iterations", 1)
        
        print(f"   Matrix multiply: {size}x{size} matrix, {iterations} iterations")
        
        total_flops = 0
        start_time = time.time()
        result_shape = None
        
        if HAS_NUMPY:
            for i in range(iterations):
                # Create random matrices (simulating work)
                a = np.random.rand(size, size).astype(np.float32)
                b = np.random.rand(size, size).astype(np.float32)
                
                # Perform multiplication
                c = np.dot(a, b)
                result_shape = c.shape
                
                # Calculate FLOPS (2 * size^3 per multiplication)
                total_flops += 2 * size * size * size
        else:
            # Fallback implementation without numpy
            for i in range(iterations):
                # Simulate matrix operations with basic math
                for row in range(size):
                    for col in range(size):
                        for k in range(size):
                            # Simulate one multiply-add operation
                            a_val = random.random()
                            b_val = random.random()
                            result = a_val * b_val
                            total_flops += 2  # multiply + add
                result_shape = (size, size)
            
        end_time = time.time()
        duration = end_time - start_time
        
        return {
            "result_type": "matrix_multiply",
            "duration_seconds": duration,
            "total_flops": total_flops,
            "flops_per_second": total_flops / duration if duration > 0 else 0,
            "matrix_size": size,
            "iterations": iterations,
            "result_shape": result_shape,
            "used_numpy": HAS_NUMPY
        }
    
    async def _execute_simple_training(self, subtask: SubTask) -> Dict[str, Any]:
        """Execute simple ML training task"""
        data = subtask.subtask_data
        
        # Simulate training work
        epochs = data.get("epochs", 5)
        batch_size = data.get("batch_size", 32)
        model_size = data.get("model_size", 1000)
        
        print(f"   Training: {epochs} epochs, batch size {batch_size}, model size {model_size}")
        
        start_time = time.time()
        total_samples = 0
        
        for epoch in range(epochs):
            # Simulate training batches
            for batch in range(10):  # 10 batches per epoch
                if HAS_NUMPY:
                    # Simulate forward pass
                    weights = np.random.rand(model_size, 10).astype(np.float32)
                    data_batch = np.random.rand(batch_size, model_size).astype(np.float32)
                    
                    # Forward pass
                    output = np.dot(data_batch, weights)
                    
                    # Simulate backward pass
                    grad = np.random.rand(*weights.shape).astype(np.float32)
                    weights -= 0.01 * grad  # Gradient descent step
                else:
                    # Fallback implementation
                    for sample in range(batch_size):
                        # Simulate forward pass calculations
                        for neuron in range(10):
                            activation = 0
                            for feature in range(model_size):
                                weight = random.random()
                                input_val = random.random()
                                activation += weight * input_val
                            # Apply simple activation
                            output_val = 1 / (1 + math.exp(-activation)) if activation > -500 else 0
                
                total_samples += batch_size
                
                # Small delay to simulate realistic training time
                time.sleep(0.01)
        
        end_time = time.time()
        duration = end_time - start_time
        
        return {
            "result_type": "simple_training",
            "duration_seconds": duration,
            "epochs_completed": epochs,
            "total_samples": total_samples,
            "samples_per_second": total_samples / duration if duration > 0 else 0,
            "final_loss": random.uniform(0.1, 1.0),  # Simulate loss
            "used_numpy": HAS_NUMPY
        }
    
    async def _execute_data_processing(self, subtask: SubTask) -> Dict[str, Any]:
        """Execute data processing task"""
        data = subtask.subtask_data
        
        # Simulate data processing
        data_size = data.get("data_size", 10000)
        operations = data.get("operations", ["filter", "map", "reduce"])
        
        print(f"   Data processing: {data_size} items, ops: {operations}")
        
        start_time = time.time()
        
        if HAS_NUMPY:
            # Generate sample data
            dataset = np.random.rand(data_size).astype(np.float32)
            
            # Apply operations
            for op in operations:
                if op == "filter":
                    dataset = dataset[dataset > 0.5]
                elif op == "map":
                    dataset = dataset * 2
                elif op == "reduce":
                    dataset = np.array([np.sum(dataset)])
                elif op == "sort":
                    dataset = np.sort(dataset)
        else:
            # Fallback implementation
            dataset = [random.random() for _ in range(data_size)]
            
            # Apply operations
            for op in operations:
                if op == "filter":
                    dataset = [x for x in dataset if x > 0.5]
                elif op == "map":
                    dataset = [x * 2 for x in dataset]
                elif op == "reduce":
                    dataset = [sum(dataset)]
                elif op == "sort":
                    dataset = sorted(dataset)
                
        end_time = time.time()
        duration = end_time - start_time
        
        return {
            "result_type": "data_processing",
            "duration_seconds": duration,
            "input_size": data_size,
            "output_size": len(dataset),
            "operations": operations,
            "processing_rate": data_size / duration if duration > 0 else 0,
            "final_result": float(dataset[0]) if len(dataset) > 0 else None,
            "used_numpy": HAS_NUMPY
        }
    
    async def _execute_dummy_task(self, subtask: SubTask) -> Dict[str, Any]:
        """Execute a dummy computational task"""
        duration = subtask.subtask_data.get("duration", 2)
        
        print(f"   Dummy task: {duration} seconds")
        
        start_time = time.time()
        
        # Simulate work
        result = 0
        iterations = int(duration * 1000)
        for i in range(iterations):
            if HAS_NUMPY:
                result += np.sin(i) * np.cos(i)
            else:
                result += math.sin(i) * math.cos(i)
            if i % 100 == 0:
                time.sleep(0.001)  # Small delay
                
        end_time = time.time()
        
        return {
            "result_type": "dummy_task",
            "duration_seconds": end_time - start_time,
            "iterations": iterations,
            "result": float(result)
        }

class SimpleTrainingService:
    """Simple gRPC-style service for distributed training communication"""
    
    def __init__(self, device_id: str):
        self.device_id = device_id
        self.running = False
        self.server_port = None
        
    def start_server(self, port: int = 0):
        """Start training service server (iPad/worker)"""
        try:
            if HAS_GRPC:
                self.server = grpc.server(concurrent.futures.ThreadPoolExecutor(max_workers=4))
                # In a real implementation, we'd add the generated gRPC service here
                # For now, we'll use HTTP as a simple alternative
                pass
            
            # Use a simple HTTP server for communication
            self.server_port = port if port > 0 else self._find_available_port()
            self.running = True
            
            # Start server in background thread
            threading.Thread(target=self._run_http_server, daemon=True).start()
            print(f"ðŸš€ Training service started on port {self.server_port}")
            return self.server_port
            
        except Exception as e:
            print(f"âŒ Failed to start training service: {e}")
            return None
    
    def _find_available_port(self) -> int:
        """Find an available port for the server"""
        import socket
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
            s.bind(('', 0))
            return s.getsockname()[1]
    
    def _run_http_server(self):
        """Run a simple HTTP server for training communication"""
        try:
            from http.server import HTTPServer, BaseHTTPRequestHandler
            import json
            
            class TrainingHandler(BaseHTTPRequestHandler):
                def do_POST(self):
                    if self.path == '/train_batch':
                        try:
                            content_length = int(self.headers['Content-Length'])
                            post_data = self.rfile.read(content_length)
                            batch_data = json.loads(post_data.decode('utf-8'))
                            
                            # Process the training batch
                            batch = TrainingBatch(**batch_data)
                            result = self.server.training_manager.process_training_batch(batch)
                            
                            # Send response
                            self.send_response(200)
                            self.send_header('Content-type', 'application/json')
                            self.end_headers()
                            self.wfile.write(json.dumps(result).encode('utf-8'))
                            
                        except Exception as e:
                            self.send_response(500)
                            self.end_headers()
                            self.wfile.write(f"Error: {str(e)}".encode('utf-8'))
                    else:
                        self.send_response(404)
                        self.end_headers()
                
                def log_message(self, format, *args):
                    pass  # Suppress HTTP server logs
            
            # Store reference to training manager
            TrainingHandler.server = self
            
            httpd = HTTPServer(('', self.server_port), TrainingHandler)
            while self.running:
                httpd.handle_request()
                
        except Exception as e:
            print(f"âŒ HTTP server error: {e}")
    
    def send_training_batch(self, target_address: str, target_port: int, batch: TrainingBatch) -> Optional[Dict[str, Any]]:
        """Send training batch to worker device (MacBook â†’ iPad)"""
        try:
            import urllib.request
            import json
            
            url = f"http://{target_address}:{target_port}/train_batch"
            batch_data = {
                'batch_id': batch.batch_id,
                'job_id': batch.job_id,
                'epoch': batch.epoch,
                'batch_index': batch.batch_index,
                'data': batch.data,
                'labels': batch.labels,
                'model_weights': batch.model_weights,
                'learning_rate': batch.learning_rate
            }
            
            data = json.dumps(batch_data).encode('utf-8')
            request = urllib.request.Request(url, data=data, headers={'Content-Type': 'application/json'})
            
            with urllib.request.urlopen(request, timeout=30) as response:
                result_data = json.loads(response.read().decode('utf-8'))
                return result_data
                
        except Exception as e:
            print(f"âŒ Failed to send batch to {target_address}:{target_port}: {e}")
            return None
    
    def stop_server(self):
        """Stop the training service"""
        self.running = False

class TinygradMNISTModel:
    """Real MNIST neural network using Tinygrad (Official Tutorial Implementation)"""
    
    def __init__(self):
        self.model = None
        self.optimizer = None
        self.X_train = None
        self.Y_train = None
        self.X_test = None
        self.Y_test = None
        self.is_built = False
        self.jit_step = None
        
        if HAS_TINYGRAD:
            try:
                self._build_official_model()
                self.is_built = True
            except Exception as e:
                print(f"âš ï¸  Tinygrad model build failed: {e}")
                self.is_built = False
        else:
            print("âš ï¸  Tinygrad not available - using fallback simulation")
    
    def _build_official_model(self):
        """Build MNIST model following official Tinygrad tutorial"""
        print("ðŸ§  Building official Tinygrad MNIST model...")
        
        # Load real MNIST data
        print("ðŸ“¥ Loading MNIST dataset...")
        self.X_train, self.Y_train, self.X_test, self.Y_test = mnist()
        print(f"âœ… MNIST loaded: train={self.X_train.shape}, test={self.X_test.shape}")
        
        # Official MNIST model from Tinygrad docs
        class Model:
            def __init__(self):
                self.l1 = nn.Conv2d(1, 32, kernel_size=(3,3))
                self.l2 = nn.Conv2d(32, 64, kernel_size=(3,3))
                self.l3 = nn.Linear(1600, 10)

            def __call__(self, x: Tensor) -> Tensor:
                x = self.l1(x).relu().max_pool2d((2,2))
                x = self.l2(x).relu().max_pool2d((2,2))
                return self.l3(x.flatten(1).dropout(0.5))
        
        self.model = Model()
        
        # Use official get_parameters function
        self.optimizer = Adam(get_parameters(self.model))
        
        print("âœ… Official MNIST model built")
        
        # Test untrained model
        Tensor.training = False
        acc = (self.model(self.X_test).argmax(axis=1) == self.Y_test).mean()
        print(f"ðŸ“Š Untrained accuracy: {acc.item()*100:.2f}% (random baseline)")
        
        # Create JIT training function
        batch_size = 32
        
        def step():
            Tensor.training = True
            samples = Tensor.randint(batch_size, high=self.X_train.shape[0])
            X, Y = self.X_train[samples], self.Y_train[samples]
            
            self.optimizer.zero_grad()
            loss = self.model(X).sparse_categorical_crossentropy(Y)
            loss.backward()
            self.optimizer.step()
            return loss
        
        self.jit_step = TinyJit(step)
        print("ðŸš€ JIT training step compiled")
    
    def train_steps_official(self, num_steps: int = 100) -> Tuple[float, float]:
        """Train using official Tinygrad MNIST method"""
        if not HAS_TINYGRAD or not self.is_built or self.jit_step is None:
            # Fallback simulation
            epoch_progress = num_steps / 200.0
            loss = 2.0 - 1.8 * epoch_progress + random.uniform(-0.1, 0.1)
            acc = 0.1 + 0.85 * epoch_progress + random.uniform(-0.05, 0.05)
            return max(0.01, loss), max(0.0, min(1.0, acc))
        
        print(f"ðŸ‹ï¸â€â™‚ï¸ Training {num_steps} steps using official Tinygrad method...")
        
        # Training loop using JIT compiled step
        for i in range(num_steps):
            loss = self.jit_step()
            
            if i % max(1, num_steps // 5) == 0:
                # Evaluate current accuracy
                Tensor.training = False
                acc = (self.model(self.X_test).argmax(axis=1) == self.Y_test).mean().item()
                print(f"   Step {i:3d}: loss={loss.item():.3f}, acc={acc*100:.2f}%")
        
        # Final evaluation
        Tensor.training = False
        final_acc = (self.model(self.X_test).argmax(axis=1) == self.Y_test).mean().item()
        final_loss = loss.item() if 'loss' in locals() else 0.1
        
        print(f"ðŸŽ¯ Final result: {final_acc*100:.2f}% accuracy")
        return final_loss, final_acc
    
    def forward(self, x):
        """Forward pass through the network"""
        if not HAS_TINYGRAD or not self.is_built:
            return None
            
        # Flatten input if needed
        if len(x.shape) > 2:
            x = x.reshape(x.shape[0], -1)
        
        # Forward pass: 784 â†’ 256 â†’ 128 â†’ 10
        x = self.fc1(x).relu()
        x = self.fc2(x).relu()
        x = self.fc3(x)  # No activation on output layer
        
        return x
    
    def compute_loss_and_accuracy(self, logits, targets):
        """Compute cross-entropy loss and accuracy"""
        if not HAS_TINYGRAD:
            return None, 0.0
        
        # Cross-entropy loss
        loss = logits.sparse_categorical_crossentropy(targets)
        
        # Compute accuracy
        predictions = logits.argmax(axis=-1)
        accuracy = (predictions == targets).mean().item()
        
        return loss, accuracy
    
    def train_batch(self, inputs, targets) -> Tuple[float, float]:
        """Train on a batch and return loss and accuracy"""
        if not HAS_TINYGRAD or not self.is_built:
            # Fallback simulation when Tinygrad not available
            epoch_progress = getattr(self, 'epoch_progress', 0.0)
            loss = 2.0 - 1.8 * epoch_progress + random.uniform(-0.1, 0.1)
            acc = 0.1 + 0.85 * epoch_progress + random.uniform(-0.05, 0.05)
            return max(0.01, loss), max(0.0, min(1.0, acc))
        
        try:
            # Enable training mode
            Tensor.training = True
            
            # Ensure inputs and targets are proper tensors
            if not isinstance(inputs, Tensor):
                inputs = Tensor(inputs)
            if not isinstance(targets, Tensor):
                targets = Tensor(targets)
            
            # Forward pass
            logits = self.forward(inputs)
            if logits is None:
                raise ValueError("Forward pass returned None")
            
            # Compute loss using cross-entropy
            loss = logits.sparse_categorical_crossentropy(targets).mean()
            
            # Compute accuracy
            predictions = logits.argmax(axis=-1)
            accuracy = (predictions == targets).mean()
            
            # Backward pass
            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()
            
            return loss.item(), accuracy.item()
            
        except Exception as e:
            print(f"âš ï¸  Training batch failed: {e}")
            # Return fallback values
            return 1.0, 0.1
    
    def evaluate_batch(self, inputs, targets) -> Tuple[float, float]:
        """Evaluate on a batch and return loss and accuracy"""
        if not HAS_TINYGRAD:
            # Fallback simulation
            return 0.5, 0.8
        
        # Real Tinygrad evaluation
        Tensor.training = False
        
        # Forward pass
        logits = self.forward(inputs)
        
        # Compute loss and accuracy
        loss, accuracy = self.compute_loss_and_accuracy(logits, targets)
        
        return loss.item(), accuracy
    
    def get_gradients(self) -> Dict[str, Any]:
        """Get gradients as numpy arrays for distributed training"""
        if not HAS_TINYGRAD or not self.is_built:
            return {}
        
        gradients = {}
        try:
            # Get gradients from each layer
            layer_names = ['fc1', 'fc2', 'fc3']
            for i, layer_name in enumerate(layer_names):
                layer = getattr(self, layer_name, None)
                if layer is not None:
                    if hasattr(layer, 'weight') and hasattr(layer.weight, 'grad') and layer.weight.grad is not None:
                        gradients[f"{layer_name}_weight"] = layer.weight.grad.numpy()
                    if hasattr(layer, 'bias') and hasattr(layer.bias, 'grad') and layer.bias.grad is not None:
                        gradients[f"{layer_name}_bias"] = layer.bias.grad.numpy()
        except Exception as e:
            print(f"Error getting gradients: {e}")
        
        return gradients
    
    def apply_gradients(self, gradients: Dict[str, Any], learning_rate: float = 0.001):
        """Apply gradients from distributed training"""
        if not HAS_TINYGRAD:
            return
        
        for i, layer in enumerate(self.layers):
            weight_key = f"layer_{i}_weight"
            bias_key = f"layer_{i}_bias"
            
            if weight_key in gradients and hasattr(layer, 'weight'):
                try:
                    grad_tensor = Tensor(gradients[weight_key])
                    layer.weight = layer.weight - learning_rate * grad_tensor
                except Exception as e:
                    print(f"Error applying weight gradient: {e}")
                
            if bias_key in gradients and hasattr(layer, 'bias'):
                try:
                    grad_tensor = Tensor(gradients[bias_key])
                    layer.bias = layer.bias - learning_rate * grad_tensor
                except Exception as e:
                    print(f"Error applying bias gradient: {e}")
    
    def get_state_dict(self) -> Dict[str, Any]:
        """Get model parameters as dictionary"""
        if not HAS_TINYGRAD or not self.is_built:
            return {}
        
        state_dict = {}
        try:
            layer_names = ['fc1', 'fc2', 'fc3']
            for layer_name in layer_names:
                layer = getattr(self, layer_name, None)
                if layer is not None:
                    if hasattr(layer, 'weight'):
                        state_dict[f"{layer_name}_weight"] = layer.weight.numpy()
                    if hasattr(layer, 'bias'):
                        state_dict[f"{layer_name}_bias"] = layer.bias.numpy()
        except Exception as e:
            print(f"Error getting state dict: {e}")
        
        return state_dict
    
    def load_state_dict(self, state_dict: Dict[str, Any]):
        """Load model parameters from dictionary"""
        if not HAS_TINYGRAD or not self.is_built:
            return
        
        try:
            layer_names = ['fc1', 'fc2', 'fc3']
            for layer_name in layer_names:
                layer = getattr(self, layer_name, None)
                if layer is not None:
                    weight_key = f"{layer_name}_weight"
                    bias_key = f"{layer_name}_bias"
                    
                    if weight_key in state_dict and hasattr(layer, 'weight'):
                        layer.weight = Tensor(state_dict[weight_key])
                        
                    if bias_key in state_dict and hasattr(layer, 'bias'):
                        layer.bias = Tensor(state_dict[bias_key])
        except Exception as e:
            print(f"Error loading state dict: {e}")

class DistributedTrainingManager:
    """Manages distributed neural network training across multiple devices"""
    
    def __init__(self, device_id: str, is_master: bool = False):
        self.device_id = device_id
        self.is_master = is_master
        self.training_jobs: Dict[str, DistributedTrainingJob] = {}
        self.pending_batches: Dict[str, TrainingBatch] = {}
        self.completed_gradients: Dict[str, List[Dict[str, Any]]] = {}
        self.tinygrad_model: Optional[TinygradMNISTModel] = None
        
    def create_neural_network(self, input_size: int, hidden_sizes: List[int], output_size: int) -> Dict[str, Any]:
        """Create a simple neural network architecture"""
        layers = []
        prev_size = input_size
        
        # Hidden layers
        for i, hidden_size in enumerate(hidden_sizes):
            layers.append({
                "name": f"hidden_{i}",
                "type": "dense",
                "input_size": prev_size,
                "output_size": hidden_size,
                "activation": "relu"
            })
            prev_size = hidden_size
            
        # Output layer
        layers.append({
            "name": "output",
            "type": "dense", 
            "input_size": prev_size,
            "output_size": output_size,
            "activation": "softmax"
        })
        
        return {
            "layers": layers,
            "input_size": input_size,
            "output_size": output_size,
            "total_parameters": self._count_parameters(layers)
        }
    
    def _count_parameters(self, layers: List[Dict[str, Any]]) -> int:
        """Count total parameters in the network"""
        total = 0
        for layer in layers:
            if layer["type"] == "dense":
                # weights + biases
                total += layer["input_size"] * layer["output_size"] + layer["output_size"]
        return total
    
    def initialize_weights(self, model_config: Dict[str, Any]) -> Dict[str, Any]:
        """Initialize neural network weights"""
        weights = {}
        
        for layer in model_config["layers"]:
            layer_name = layer["name"]
            input_size = layer["input_size"]
            output_size = layer["output_size"]
            
            if HAS_NUMPY:
                # Xavier initialization
                limit = (6.0 / (input_size + output_size)) ** 0.5
                weights[f"{layer_name}_weights"] = np.random.uniform(
                    -limit, limit, (input_size, output_size)
                ).astype(np.float32).tolist()
                weights[f"{layer_name}_bias"] = np.zeros(output_size).astype(np.float32).tolist()
            else:
                # Simple random initialization
                limit = 0.1
                weights[f"{layer_name}_weights"] = [
                    [random.uniform(-limit, limit) for _ in range(output_size)]
                    for _ in range(input_size)
                ]
                weights[f"{layer_name}_bias"] = [0.0] * output_size
                
        return weights
    
    def create_mnist_data(self, num_samples: int) -> Tuple[List[List[float]], List[int]]:
        """Create high-quality synthetic MNIST data with strong patterns"""
        data = []
        labels = []
        
        print(f"ðŸŽ¨ Generating {num_samples} high-quality MNIST samples...")
        
        for i in range(num_samples):
            digit_class = i % 10
            
            if HAS_NUMPY:
                # Create 28x28 image with strong digit patterns
                image = np.zeros((28, 28), dtype=np.float32)
                
                # Add noise
                noise = np.random.normal(0, 0.1, (28, 28))
                image += noise
                
                # Create strong digit patterns
                if digit_class == 0:  # Circle
                    center = (14, 14)
                    for y in range(28):
                        for x in range(28):
                            dist = ((x - center[0])**2 + (y - center[1])**2)**0.5
                            if 8 < dist < 12:  # Ring pattern
                                image[y, x] = 0.8 + np.random.normal(0, 0.1)
                
                elif digit_class == 1:  # Vertical line
                    for y in range(5, 23):
                        for x in range(12, 16):
                            image[y, x] = 0.9 + np.random.normal(0, 0.1)
                
                elif digit_class == 2:  # Horizontal lines
                    # Top line
                    for x in range(8, 20):
                        for y in range(6, 10):
                            image[y, x] = 0.8 + np.random.normal(0, 0.1)
                    # Bottom line
                    for x in range(8, 20):
                        for y in range(18, 22):
                            image[y, x] = 0.8 + np.random.normal(0, 0.1)
                
                elif digit_class == 3:  # Curved pattern
                    for y in range(6, 22):
                        x = int(14 + 4 * np.sin(y * 0.3))
                        if 0 <= x < 28:
                            for dx in range(-1, 2):
                                if 0 <= x + dx < 28:
                                    image[y, x + dx] = 0.8 + np.random.normal(0, 0.1)
                
                elif digit_class == 4:  # T-shape
                    # Vertical line
                    for y in range(10, 22):
                        for x in range(13, 16):
                            image[y, x] = 0.8 + np.random.normal(0, 0.1)
                    # Horizontal line
                    for x in range(8, 20):
                        for y in range(10, 13):
                            image[y, x] = 0.8 + np.random.normal(0, 0.1)
                
                elif digit_class == 5:  # S-shape
                    # Top horizontal
                    for x in range(8, 18):
                        for y in range(6, 9):
                            image[y, x] = 0.8 + np.random.normal(0, 0.1)
                    # Bottom horizontal
                    for x in range(10, 20):
                        for y in range(18, 21):
                            image[y, x] = 0.8 + np.random.normal(0, 0.1)
                
                elif digit_class == 6:  # Loop
                    for y in range(8, 20):
                        for x in range(10, 13):
                            image[y, x] = 0.8 + np.random.normal(0, 0.1)
                        if y > 14:
                            for x in range(13, 18):
                                image[y, x] = 0.8 + np.random.normal(0, 0.1)
                
                elif digit_class == 7:  # Top line + diagonal
                    # Top line
                    for x in range(8, 20):
                        for y in range(6, 9):
                            image[y, x] = 0.8 + np.random.normal(0, 0.1)
                    # Diagonal
                    for i in range(12):
                        y = 9 + i
                        x = 18 - i
                        if 0 <= y < 28 and 0 <= x < 28:
                            image[y, x] = 0.8 + np.random.normal(0, 0.1)
                
                elif digit_class == 8:  # Double circle
                    # Top circle
                    for y in range(6, 14):
                        for x in range(10, 18):
                            if abs((x-14)**2 + (y-10)**2 - 9) < 3:
                                image[y, x] = 0.8 + np.random.normal(0, 0.1)
                    # Bottom circle
                    for y in range(14, 22):
                        for x in range(10, 18):
                            if abs((x-14)**2 + (y-18)**2 - 9) < 3:
                                image[y, x] = 0.8 + np.random.normal(0, 0.1)
                
                elif digit_class == 9:  # Circle with tail
                    # Circle
                    center = (14, 11)
                    for y in range(6, 16):
                        for x in range(10, 18):
                            dist = ((x - center[0])**2 + (y - center[1])**2)**0.5
                            if abs(dist - 4) < 1.5:
                                image[y, x] = 0.8 + np.random.normal(0, 0.1)
                    # Tail
                    for y in range(16, 22):
                        for x in range(15, 18):
                            image[y, x] = 0.8 + np.random.normal(0, 0.1)
                
                # Normalize and flatten
                image = np.clip(image, 0, 1)
                sample = image.flatten().tolist()
                
            else:
                # Fallback implementation
                sample = [random.random() * 0.1 for _ in range(784)]  # Mostly zeros
                
                # Add simple patterns
                if digit_class == 1:  # Vertical line
                    for i in range(10, 18):  # Rows 10-17
                        sample[i * 28 + 14] = 0.9  # Column 14
                elif digit_class == 0:  # Some pattern for 0
                    for i in range(300, 500):  # Center area
                        if i < 784:
                            sample[i] = 0.5
            
            data.append(sample)
            labels.append(digit_class)
            
        print(f"âœ… Generated high-quality MNIST dataset: {len(data)} samples")
        return data, labels
    
    def create_training_data(self, num_samples: int, input_size: int, num_classes: int) -> Tuple[List[List[float]], List[int]]:
        """Create training data - use MNIST if appropriate size, else synthetic"""
        if input_size == 784 and num_classes == 10:
            # MNIST configuration
            return self.create_mnist_data(num_samples)
        else:
            # Generic synthetic data
            data = []
            labels = []
            
            for _ in range(num_samples):
                if HAS_NUMPY:
                    sample = np.random.randn(input_size).astype(np.float32).tolist()
                else:
                    sample = [random.gauss(0, 1) for _ in range(input_size)]
                
                # Create synthetic label based on sample features
                label = abs(hash(str(sample[:3]))) % num_classes
                
                data.append(sample)
                labels.append(label)
                
            return data, labels
    
    def start_distributed_training(self, slave_devices: List[str], model_config: Dict[str, Any], 
                                 training_config: Dict[str, Any]) -> str:
        """Start a new distributed training job (Master only)"""
        if not self.is_master:
            raise ValueError("Only master device can start distributed training")
            
        job_id = str(uuid.uuid4())
        
        # Create training data
        data, labels = self.create_training_data(
            training_config.get("num_samples", 1000),
            model_config["input_size"],
            model_config["output_size"]
        )
        
        job = DistributedTrainingJob(
            job_id=job_id,
            model_config=model_config,
            training_config=training_config,
            master_device_id=self.device_id,
            slave_devices=slave_devices,
            total_epochs=training_config.get("epochs", 10),
            model_parameters=self.initialize_weights(model_config),
            training_data=list(zip(data, labels))
        )
        
        self.training_jobs[job_id] = job
        
        # Initialize Tinygrad model for real computation
        if HAS_TINYGRAD:
            try:
                print("ðŸ”§ Initializing Tinygrad model...")
                self.tinygrad_model = TinygradMNISTModel(
                    input_size=model_config["input_size"],
                    hidden_sizes=[256, 128],  # Use fixed architecture that works
                    output_size=model_config["output_size"]
                )
                if self.tinygrad_model.is_built:
                    print("âœ… Tinygrad model ready for training")
                else:
                    print("âš ï¸  Tinygrad model not built, using simulation")
                    self.tinygrad_model = None
            except Exception as e:
                print(f"âš ï¸  Failed to create Tinygrad model: {e}")
                print("ðŸ”„ Will use simulation mode instead")
                self.tinygrad_model = None
        print(f"ðŸŽ¯ Started distributed training job {job_id[:8]}...")
        print(f"   Model: {len(model_config['layers'])} layers, {model_config['total_parameters']} parameters")
        print(f"   Data: {len(data)} samples")
        print(f"   Workers: {len(slave_devices)} devices")
        
        return job_id
    
    def distribute_epoch_batches(self, job_id: str, device_workloads: Optional[Dict[str, float]] = None) -> List[TrainingBatch]:
        """Distribute training batches for current epoch to slave devices with configurable workloads"""
        if job_id not in self.training_jobs:
            return []
            
        job = self.training_jobs[job_id]
        batch_size = job.training_config.get("batch_size", 32)
        num_slaves = len(job.slave_devices)
        
        if num_slaves == 0:
            return []
        
        # Use device workloads if provided, otherwise equal distribution
        if device_workloads is None:
            device_workloads = {device_id: 1.0 for device_id in job.slave_devices}
        
        # Normalize workloads to sum to 1.0
        total_workload = sum(device_workloads.get(device_id, 1.0) for device_id in job.slave_devices)
        normalized_workloads = {
            device_id: device_workloads.get(device_id, 1.0) / total_workload 
            for device_id in job.slave_devices
        }
        
        # Split data into batches
        batches = []
        data = job.training_data
        total_samples = len(data)
        
        print(f"ðŸ“Š Workload distribution:")
        for device_id, workload in normalized_workloads.items():
            samples_for_device = int(total_samples * workload)
            print(f"   {device_id[:8]}...: {workload*100:.1f}% ({samples_for_device} samples)")
        
        # Distribute data based on workload percentages
        current_idx = 0
        for i, device_id in enumerate(job.slave_devices):
            workload_percentage = normalized_workloads[device_id]
            samples_for_device = int(total_samples * workload_percentage)
            
            # For last device, take remaining samples to avoid rounding issues
            if i == len(job.slave_devices) - 1:
                samples_for_device = total_samples - current_idx
            
            if samples_for_device > 0:
                device_data = data[current_idx:current_idx + samples_for_device]
                current_idx += samples_for_device
                
                # Split device data into batches
                for batch_idx in range(0, len(device_data), batch_size):
                    batch_data = device_data[batch_idx:batch_idx + batch_size]
                    
                    if len(batch_data) > 0:
                        batch_inputs = [sample[0] for sample in batch_data]
                        batch_labels = [sample[1] for sample in batch_data]
                        
                        batch = TrainingBatch(
                            batch_id=str(uuid.uuid4()),
                            job_id=job_id,
                            epoch=job.current_epoch,
                            batch_index=len(batches),
                            data=batch_inputs,
                            labels=batch_labels,
                            model_weights=job.model_parameters,
                            learning_rate=job.training_config.get("learning_rate", 0.01)
                        )
                        
                        batches.append(batch)
                        
        return batches
    
    def process_training_batch(self, batch: TrainingBatch) -> Dict[str, Any]:
        """Process a training batch using real Tinygrad neural network"""
        device_name = platform.machine() if hasattr(platform, 'machine') else "Unknown"
        print(f"ðŸ”„ [{device_name}] Processing batch {batch.batch_id[:8]} with {len(batch.data)} samples")
        print(f"   ðŸ§® Using {'Tinygrad' if HAS_TINYGRAD else 'simulation'} for computation")
        
        start_time = time.time()
        
        if HAS_TINYGRAD and self.tinygrad_model is not None and self.use_tinygrad:
            # REAL NEURAL NETWORK TRAINING WITH TINYGRAD
            print(f"   âš¡ Real computation on {device_name} using Tinygrad")
            
            try:
                # Convert data to Tinygrad tensors
                inputs = Tensor(batch.data)  # Shape: [batch_size, 784]
                targets = Tensor(batch.labels)  # Shape: [batch_size]
                
                # Load current model parameters
                if batch.model_weights:
                    state_dict = {}
                    for key, value in batch.model_weights.items():
                        if key.startswith('layer_'):
                            state_dict[key] = value
                    self.tinygrad_model.load_state_dict(state_dict)
                
                # Train using official method (50 steps per batch)
                loss, accuracy = self.tinygrad_model.train_steps_official(50)
                
                # Get real gradients
                gradients = self.tinygrad_model.get_gradients()
                
                # Get updated model state
                updated_state = self.tinygrad_model.get_state_dict()
                
                end_time = time.time()
                
                print(f"   âœ… Real training completed: Loss={loss:.4f}, Acc={accuracy:.3f}")
                
                return {
                    "batch_id": batch.batch_id,
                    "job_id": batch.job_id,
                    "epoch": batch.epoch,
                    "gradients": gradients,
                    "loss": loss,
                    "accuracy": accuracy,
                    "num_samples": len(batch.data),
                    "computation_time": end_time - start_time,
                    "device_id": self.device_id,
                    "device_name": device_name,
                    "used_tinygrad": True,
                    "updated_model_state": updated_state,
                    "computation_proof": {
                        "framework": "Tinygrad",
                        "device": device_name,
                        "real_computation": True,
                        "gradient_norms": {k: float(np.linalg.norm(v)) if HAS_NUMPY and hasattr(v, '__len__') and len(v) > 0 else 0.0 for k, v in gradients.items()}
                    }
                }
            except Exception as e:
                print(f"   âŒ Tinygrad error: {str(e)}")
                print(f"   ðŸ” Error type: {type(e).__name__}")
                if hasattr(e, '__traceback__'):
                    import traceback
                    print(f"   ðŸ“ Error location: {traceback.format_exc().splitlines()[-3:-1]}")
                print("   ðŸ”„ Falling back to simulation...")
                # Fall through to simulation code below
        
        else:
            # FALLBACK SIMULATION (when Tinygrad not available)
            print(f"   âš ï¸  Fallback simulation on {device_name}")
            
            # Simulate realistic training
            epoch = batch.epoch
            learning_progress = min(1.0, epoch / 10.0)
            
            # Simulate gradients
            gradients = {}
            if batch.model_weights:
                for layer_name, weights in batch.model_weights.items():
                    if HAS_NUMPY and isinstance(weights, list):
                        if len(weights) > 0 and isinstance(weights[0], list):  # 2D weights
                            grad = np.random.randn(len(weights), len(weights[0])) * 0.01
                            gradients[layer_name] = grad.tolist()
                        else:  # 1D bias
                            grad = np.random.randn(len(weights)) * 0.005
                            gradients[layer_name] = grad.tolist()
            
            # Simulate improving loss and accuracy
            initial_loss = 2.3
            final_loss = 0.05
            loss = initial_loss - (initial_loss - final_loss) * learning_progress
            loss += random.uniform(-0.1, 0.1)
            loss = max(0.01, loss)
            
            initial_accuracy = 0.1
            final_accuracy = 0.98
            accuracy = initial_accuracy + (final_accuracy - initial_accuracy) * learning_progress
            accuracy += random.uniform(-0.03, 0.03)
            accuracy = max(0.0, min(1.0, accuracy))
            
            # Simulate computation time
            time.sleep(len(batch.data) * 0.003)
            
            end_time = time.time()
            
            return {
                "batch_id": batch.batch_id,
                "job_id": batch.job_id,
                "epoch": batch.epoch,
                "gradients": gradients,
                "loss": loss,
                "accuracy": accuracy,
                "num_samples": len(batch.data),
                "computation_time": end_time - start_time,
                "device_id": self.device_id,
                "device_name": device_name,
                "used_tinygrad": False,
                "computation_proof": {
                    "framework": "Simulation",
                    "device": device_name,
                    "real_computation": False
                }
            }
    
    def aggregate_gradients(self, job_id: str, gradient_results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Aggregate gradients from all slaves (Master only)"""
        if not gradient_results:
            return {}
            
        # Average gradients across all devices
        aggregated = {}
        num_devices = len(gradient_results)
        
        # Get parameter names from first result
        first_result = gradient_results[0]
        param_names = first_result["gradients"].keys()
        
        for param_name in param_names:
            if HAS_NUMPY:
                # Stack gradients and compute average
                grads = [np.array(result["gradients"][param_name]) for result in gradient_results]
                avg_grad = np.mean(grads, axis=0)
                aggregated[param_name] = avg_grad.tolist()
            else:
                # Manual averaging for fallback
                grads = [result["gradients"][param_name] for result in gradient_results]
                if isinstance(grads[0][0], list):  # 2D weights
                    rows, cols = len(grads[0]), len(grads[0][0])
                    avg_grad = []
                    for r in range(rows):
                        row = []
                        for c in range(cols):
                            avg_val = sum(grad[r][c] for grad in grads) / num_devices
                            row.append(avg_val)
                        avg_grad.append(row)
                    aggregated[param_name] = avg_grad
                else:  # 1D bias
                    size = len(grads[0])
                    avg_grad = []
                    for i in range(size):
                        avg_val = sum(grad[i] for grad in grads) / num_devices
                        avg_grad.append(avg_val)
                    aggregated[param_name] = avg_grad
        
        # Calculate average loss and accuracy
        avg_loss = sum(result["loss"] for result in gradient_results) / num_devices
        avg_accuracy = sum(result.get("accuracy", 0.0) for result in gradient_results) / num_devices
        total_samples = sum(result["num_samples"] for result in gradient_results)
        total_computation_time = sum(result["computation_time"] for result in gradient_results)
        
        return {
            "aggregated_gradients": aggregated,
            "average_loss": avg_loss,
            "average_accuracy": avg_accuracy,
            "total_samples": total_samples,
            "total_computation_time": total_computation_time,
            "num_devices": num_devices
        }
    
    def update_model_parameters(self, job_id: str, aggregated_gradients: Dict[str, Any], learning_rate: float):
        """Update model parameters using aggregated gradients (Master only)"""
        if job_id not in self.training_jobs:
            return
            
        job = self.training_jobs[job_id]
        
        # Apply gradients to update parameters
        for param_name, gradient in aggregated_gradients.items():
            if param_name in job.model_parameters:
                if HAS_NUMPY:
                    current = np.array(job.model_parameters[param_name])
                    grad = np.array(gradient)
                    updated = current - learning_rate * grad
                    job.model_parameters[param_name] = updated.tolist()
                else:
                    # Manual parameter update
                    current = job.model_parameters[param_name]
                    if isinstance(current[0], list):  # 2D weights
                        for r in range(len(current)):
                            for c in range(len(current[r])):
                                current[r][c] -= learning_rate * gradient[r][c]
                    else:  # 1D bias
                        for i in range(len(current)):
                            current[i] -= learning_rate * gradient[i]
    
    def get_training_status(self, job_id: str) -> Optional[Dict[str, Any]]:
        """Get current training status"""
        if job_id not in self.training_jobs:
            return None
            
        job = self.training_jobs[job_id]
        
        return {
            "job_id": job_id,
            "status": job.status,
            "current_epoch": job.current_epoch,
            "total_epochs": job.total_epochs,
            "progress": (job.current_epoch / job.total_epochs) * 100,
            "master_device": job.master_device_id,
            "slave_devices": job.slave_devices,
            "model_info": {
                "layers": len(job.model_config["layers"]),
                "parameters": job.model_config["total_parameters"]
            }
        }

class DiscomputeMobile:
    def __init__(self, device_id=None, port=8080, debug=False, use_tinygrad=False):
        self.device_id = device_id or f"ios-{int(time.time())}"
        self.port = port
        self.listen_port = 5005
        self.broadcast_port = 5005
        self.running = False
        self.discovered_devices = {}
        self.device_capabilities = self.get_device_capabilities()
        self.debug = debug
        self.start_time = time.time()
        self.use_tinygrad = use_tinygrad and HAS_TINYGRAD
        
        # Task management
        self.task_executor = TaskExecutor(self.device_capabilities)
        self.submitted_tasks: Dict[str, ComputeTask] = {}
        self.task_results: Dict[str, List[SubTask]] = {}
        
        # Distributed training management
        self.training_manager = DistributedTrainingManager(self.device_id, is_master=False)
        self.is_master_device = False
        self.training_service = SimpleTrainingService(self.device_id)
        
        # Set reference for HTTP server
        self.training_service.training_manager = self.training_manager
        
        print(f"ðŸš€ Discompute Mobile Client")
        print(f"Device ID: {self.device_id}")
        print(f"Device Info: {self.device_capabilities}")
        
        if self.debug:
            self.print_network_info()
    
    def get_device_capabilities(self):
        """Detect iOS device capabilities"""
        try:
            # Try to get iOS device info
            model = platform.machine()
            if model.startswith('iPhone'):
                device_type = "iphone"
                # iPhone 16 Pro would be iPhone16,2 or similar
                if "16" in model:
                    chip = "Apple A18 Pro"
                    fp32_tflops = 2.80
                    fp16_tflops = 5.60
                    int8_tflops = 11.20
                elif "15" in model:
                    chip = "Apple A17 Pro" 
                    fp32_tflops = 2.15
                    fp16_tflops = 4.30
                    int8_tflops = 8.60
                else:
                    chip = "Apple A15 Bionic"
                    fp32_tflops = 1.37
                    fp16_tflops = 2.74
                    int8_tflops = 5.48
            elif model.startswith('iPad'):
                device_type = "ipad"
                chip = "Apple M2"  # Modern iPads use M-series
                fp32_tflops = 3.55
                fp16_tflops = 7.10
                int8_tflops = 14.20
            else:
                device_type = "ios_device"
                chip = "Unknown iOS Chip"
                fp32_tflops = 1.0
                fp16_tflops = 2.0
                int8_tflops = 4.0
                
            return {
                "model": model,
                "chip": chip,
                "type": device_type,
                "memory": 8192,  # Assume 8GB for modern iOS devices
                "flops": {
                    "fp32": fp32_tflops,
                    "fp16": fp16_tflops,
                    "int8": int8_tflops
                }
            }
        except Exception as e:
            print(f"Error detecting device capabilities: {e}")
            return {
                "model": "iOS Device",
                "chip": "Unknown",
                "type": "ios_device", 
                "memory": 4096,
                "flops": {"fp32": 1.0, "fp16": 2.0, "int8": 4.0}
            }
    
    def start_discovery(self):
        """Start UDP discovery service"""
        self.running = True
        
        # Start listening for discoveries
        listen_thread = threading.Thread(target=self.listen_for_devices, daemon=True)
        listen_thread.start()
        
        # Start broadcasting presence
        broadcast_thread = threading.Thread(target=self.broadcast_presence, daemon=True)  
        broadcast_thread.start()
        
        print(f"âœ… Discovery started on port {self.listen_port}")
        return True
    
    def listen_for_devices(self):
        """Listen for UDP discovery messages"""
        try:
            sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
            sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
            
            # Try to bind to all interfaces first, fallback to specific IP
            bind_success = False
            try:
                sock.bind(('', self.listen_port))
                bind_success = True
                print(f"ðŸ‘‚ Listening on all interfaces, port {self.listen_port}")
            except Exception as e:
                print(f"Failed to bind to all interfaces: {e}")
                # Try binding to local IP
                try:
                    local_ip = self.get_local_ip()
                    sock.bind((local_ip, self.listen_port))
                    bind_success = True
                    print(f"ðŸ‘‚ Listening on {local_ip}:{self.listen_port}")
                except Exception as e2:
                    print(f"Failed to bind to {local_ip}: {e2}")
                    # Last resort - try localhost
                    try:
                        sock.bind(('127.0.0.1', self.listen_port))
                        bind_success = True
                        print(f"ðŸ‘‚ Listening on localhost:{self.listen_port}")
                    except Exception as e3:
                        print(f"Failed to bind to localhost: {e3}")
            
            if not bind_success:
                print("âŒ Could not bind to any address for listening")
                return
                
            sock.settimeout(1.0)  # Non-blocking with timeout
            
            while self.running:
                try:
                    data, addr = sock.recvfrom(4096)
                    self.handle_discovery_message(data, addr[0])
                except socket.timeout:
                    continue
                except Exception as e:
                    if self.running:
                        print(f"Error receiving: {e}")
                        
        except Exception as e:
            print(f"Error setting up listener: {e}")
        finally:
            try:
                sock.close()
            except:
                pass
    
    def handle_discovery_message(self, data, sender_ip):
        """Handle received discovery message"""
        try:
            message = json.loads(data.decode('utf-8'))
            
            if message.get('type') == 'discovery' and message.get('node_id') != self.device_id:
                device_id = message['node_id']
                device_info = {
                    'id': device_id,
                    'name': message['device_capabilities']['model'],
                    'type': message['device_capabilities']['type'],
                    'address': sender_ip,
                    'port': message['grpc_port'],
                    'capabilities': message['device_capabilities'],
                    'last_seen': datetime.now(),
                    'priority': message.get('priority', 10)
                }
                
                is_new = device_id not in self.discovered_devices
                self.discovered_devices[device_id] = device_info
                
                if is_new:
                    print(f"ðŸ” Discovered: {device_info['name']} ({device_info['type']}) at {sender_ip}")
                    
        except Exception as e:
            print(f"Error handling discovery message: {e}")
    
    def get_local_ip(self):
        """Get the local IP address"""
        try:
            # Connect to a remote address to determine local IP
            sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
            sock.connect(("8.8.8.8", 80))
            local_ip = sock.getsockname()[0]
            sock.close()
            return local_ip
        except Exception:
            return "192.168.1.100"  # fallback
    
    def get_broadcast_addresses(self):
        """Get possible broadcast addresses for the local network"""
        try:
            local_ip = self.get_local_ip()
            # Common local network broadcast addresses
            ip_parts = local_ip.split('.')
            if ip_parts[0] == '192' and ip_parts[1] == '168':
                # 192.168.x.x network
                return [f"192.168.{ip_parts[2]}.255", "192.168.255.255"]
            elif ip_parts[0] == '10':
                # 10.x.x.x network  
                return [f"10.{ip_parts[1]}.{ip_parts[2]}.255", "10.255.255.255"]
            elif ip_parts[0] == '172':
                # 172.16-31.x.x network
                return [f"172.{ip_parts[1]}.{ip_parts[2]}.255", "172.31.255.255"]
            else:
                return ["255.255.255.255"]
        except Exception:
            return ["192.168.1.255", "192.168.0.255", "255.255.255.255"]
    
    def print_network_info(self):
        """Print network diagnostic information"""
        print("\nðŸ” Network Diagnostics:")
        try:
            local_ip = self.get_local_ip()
            print(f"Local IP: {local_ip}")
            
            broadcast_addrs = self.get_broadcast_addresses()
            print(f"Broadcast addresses: {broadcast_addrs}")
            
            # Test socket creation
            try:
                test_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
                test_sock.setsockopt(socket.SOL_SOCKET, socket.SO_BROADCAST, 1)
                print("âœ… UDP broadcast socket creation: OK")
                test_sock.close()
            except Exception as e:
                print(f"âŒ UDP broadcast socket creation: {e}")
                
            # Test binding to discovery port
            try:
                test_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
                test_sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
                test_sock.bind(('', self.listen_port))
                print(f"âœ… Discovery port {self.listen_port} binding: OK")
                test_sock.close()
            except Exception as e:
                print(f"âŒ Discovery port {self.listen_port} binding: {e}")
                
            # Test general binding
            try:
                test_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
                test_sock.bind(('', 0))  # Bind to any available port
                port = test_sock.getsockname()[1]
                print(f"âœ… General socket binding: OK (got port {port})")
                test_sock.close()
            except Exception as e:
                print(f"âŒ General socket binding: {e}")
                
            # Test if we can reach other common local IPs
            print("\nðŸŒ Network Reachability Tests:")
            test_ips = ["192.168.1.1", "192.168.0.1", "10.0.0.1"]
            for test_ip in test_ips:
                try:
                    test_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
                    test_sock.settimeout(2.0)
                    test_sock.connect((test_ip, 53))  # Try DNS port
                    print(f"âœ… Can reach {test_ip}")
                    test_sock.close()
                except Exception:
                    print(f"âŒ Cannot reach {test_ip}")
                    
            # Check what interfaces we can bind to
            print("\nðŸ”Œ Interface Binding Tests:")
            bind_tests = [
                ("All interfaces", ""),
                ("Localhost", "127.0.0.1"), 
                ("Local IP", local_ip)
            ]
            
            for name, addr in bind_tests:
                try:
                    test_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
                    test_sock.bind((addr, 0))
                    port = test_sock.getsockname()[1]
                    print(f"âœ… {name} ({addr or 'any'}): OK (port {port})")
                    test_sock.close()
                except Exception as e:
                    print(f"âŒ {name} ({addr or 'any'}): {e}")
                
        except Exception as e:
            print(f"âŒ Network diagnostics failed: {e}")
        print()

    def broadcast_presence(self):
        """Broadcast our presence every 2.5 seconds"""
        broadcast_addresses = self.get_broadcast_addresses()
        local_ip = self.get_local_ip()
        
        print(f"ðŸŒ Local IP: {local_ip}")
        print(f"ðŸ“¡ Will try broadcasting to: {broadcast_addresses}")
        
        while self.running:
            try:
                message = {
                    "type": "discovery",
                    "node_id": self.device_id,
                    "grpc_port": self.port,
                    "device_capabilities": self.device_capabilities,
                    "priority": 1,
                    "interface_name": "wifi",
                    "interface_type": "wifi",
                    "timestamp": int(time.time())
                }
                
                data = json.dumps(message).encode('utf-8')
                
                broadcast_success = False
                
                # Try multiple broadcast strategies
                for broadcast_addr in broadcast_addresses:
                    try:
                        sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
                        sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
                        sock.setsockopt(socket.SOL_SOCKET, socket.SO_BROADCAST, 1)
                        
                        # Bind to specific interface for iOS
                        try:
                            sock.bind((local_ip, 0))
                        except Exception:
                            pass  # fallback to default binding
                        
                        sock.sendto(data, (broadcast_addr, self.broadcast_port))
                        sock.close()
                        broadcast_success = True
                        if self.debug:
                            print(f"âœ… Broadcast successful to {broadcast_addr}")
                        break  # Success with this address
                        
                    except Exception as e:
                        if self.debug:
                            print(f"âŒ Broadcast failed to {broadcast_addr}: {e}")
                        if "No route to host" in str(e):
                            continue  # Try next address
                        elif "Network is unreachable" in str(e):
                            continue  # Try next address
                        else:
                            print(f"Broadcast error to {broadcast_addr}: {e}")
                
                # Fallback: try multicast
                if not broadcast_success:
                    try:
                        sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
                        sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
                        # Use multicast address for local network
                        sock.sendto(data, ('224.0.0.1', self.broadcast_port))
                        sock.close()
                        broadcast_success = True
                    except Exception as e:
                        print(f"Multicast fallback error: {e}")
                
                if broadcast_success:
                    if self.debug:
                        print(f"ðŸ“¡ Broadcasted presence ({len(self.discovered_devices)} devices known)")
                else:
                    if self.debug:
                        print(f"âš ï¸  Broadcast failed - trying unicast to known devices")
                    # Try direct unicast to previously discovered devices
                    for device_id, device in list(self.discovered_devices.items()):
                        try:
                            sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
                            sock.sendto(data, (device['address'], self.broadcast_port))
                            sock.close()
                        except Exception:
                            pass  # Silent fail for unicast
                
            except Exception as e:
                print(f"Error in broadcast loop: {e}")
            
            time.sleep(2.5)  # EXO's broadcast interval
    
    def stop_discovery(self):
        """Stop discovery service"""
        self.running = False
        print("ðŸ›‘ Discovery stopped")
    
    def list_devices(self):
        """List all discovered devices"""
        if not self.discovered_devices:
            print("No devices discovered yet")
            return
            
        print(f"\nðŸ“± Discovered {len(self.discovered_devices)} device(s):")
        print("=" * 50)
        
        for device_id, device in self.discovered_devices.items():
            print(f"Device: {device['name']}")
            print(f"  ID: {device_id}")
            print(f"  Type: {device['type']}")
            print(f"  Address: {device['address']}:{device['port']}")
            caps = device['capabilities']
            if 'flops' in caps:
                print(f"  Compute: {caps['flops']['fp32']:.2f} TFLOPS (FP32)")
            print(f"  Last seen: {device['last_seen'].strftime('%H:%M:%S')}")
            print()
    
    def test_listener(self):
        """Test if the UDP listener is working by sending a message to localhost"""
        print("ðŸ§ª Testing UDP listener...")
        try:
            # Create a test message with a different device ID
            test_message = {
                "type": "discovery",
                "node_id": f"test-device-{int(time.time())}",
                "grpc_port": 8080,
                "device_capabilities": {
                    "model": "Test Device",
                    "chip": "Test Chip",
                    "type": "test",
                    "memory": 1024,
                    "flops": {"fp32": 1.0, "fp16": 2.0, "int8": 4.0}
                },
                "priority": 1,
                "interface_name": "test",
                "interface_type": "test",
                "timestamp": int(time.time())
            }
            
            data = json.dumps(test_message).encode('utf-8')
            
            # Send to localhost
            sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
            sock.sendto(data, ('127.0.0.1', self.listen_port))
            sock.close()
            
            print("âœ… Test message sent to localhost")
            print("Check if a test device appears in 'list' command in a few seconds...")
            
        except Exception as e:
            print(f"âŒ Test failed: {e}")
    
    def send_test_message(self, target_device_id, message):
        """Send a test message to another device"""
        if target_device_id not in self.discovered_devices:
            print(f"âŒ Device {target_device_id} not found")
            return False
            
        device = self.discovered_devices[target_device_id]
        print(f"ðŸ“¤ Sending message to {device['name']}: {message}")
        
        # TODO: Implement actual gRPC message sending
        print("âœ… Message sent (placeholder - gRPC client not implemented yet)")
        return True
    
    def submit_task(self, task_type: str, task_data: Dict[str, Any], target_device: Optional[str] = None) -> str:
        """Submit a compute task to the network"""
        task_id = str(uuid.uuid4())
        
        task = ComputeTask(
            task_id=task_id,
            task_type=task_type,
            task_data=task_data,
            metadata={"submitted_by": self.device_id, "submitted_at": str(datetime.now())},
            required_capabilities=[],
            estimated_duration=task_data.get("estimated_duration", 30),
            priority=task_data.get("priority", 5),
            max_devices=task_data.get("max_devices", 1),
            target_subtasks=task_data.get("target_subtasks", 1)
        )
        
        self.submitted_tasks[task_id] = task
        
        if target_device and target_device in self.discovered_devices:
            # Send to specific device
            print(f"ðŸ“¤ Submitting task {task_id} to {target_device}")
            self._send_task_to_device(task, target_device)
        else:
            # Execute locally for now (TODO: implement distributed execution)
            print(f"ðŸ”„ Executing task {task_id} locally")
            threading.Thread(target=self._execute_task_locally, args=(task,), daemon=True).start()
            
        return task_id
    
    def _send_task_to_device(self, task: ComputeTask, device_id: str):
        """Send a task to a specific device (placeholder)"""
        # Create subtask for the target device
        subtask = SubTask(
            subtask_id=str(uuid.uuid4()),
            parent_task_id=task.task_id,
            subtask_index=0,
            subtask_data=task.task_data,
            assigned_device_id=device_id
        )
        
        # TODO: Implement actual gRPC call to send task
        # For now, simulate successful submission
        print(f"ðŸ“¡ Task {task.task_id} sent to {device_id} (simulated)")
        
        # Store the subtask
        if task.task_id not in self.task_results:
            self.task_results[task.task_id] = []
        self.task_results[task.task_id].append(subtask)
    
    def _execute_task_locally(self, task: ComputeTask):
        """Execute a task locally"""
        try:
            # Create subtask for local execution
            subtask = SubTask(
                subtask_id=str(uuid.uuid4()),
                parent_task_id=task.task_id,
                subtask_index=0,
                subtask_data=task.task_data,
                assigned_device_id=self.device_id
            )
            
            # Execute using asyncio in a separate thread
            import asyncio
            
            def run_async():
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                try:
                    result = loop.run_until_complete(self.task_executor.execute_subtask(subtask))
                    return result
                finally:
                    loop.close()
            
            completed_subtask = run_async()
            
            # Store results
            if task.task_id not in self.task_results:
                self.task_results[task.task_id] = []
            self.task_results[task.task_id].append(completed_subtask)
            
        except Exception as e:
            print(f"âŒ Error executing task {task.task_id}: {e}")
    
    def get_task_status(self, task_id: str) -> Optional[Dict[str, Any]]:
        """Get the status of a submitted task"""
        if task_id not in self.submitted_tasks:
            return None
            
        task = self.submitted_tasks[task_id]
        subtasks = self.task_results.get(task_id, [])
        
        completed_subtasks = [st for st in subtasks if st.status == "completed"]
        failed_subtasks = [st for st in subtasks if st.status == "failed"]
        running_subtasks = [st for st in subtasks if st.status == "running"]
        
        total_subtasks = len(subtasks)
        completion_percentage = (len(completed_subtasks) / total_subtasks * 100) if total_subtasks > 0 else 0
        
        return {
            "task_id": task_id,
            "task_type": task.task_type,
            "status": "completed" if len(completed_subtasks) == total_subtasks else 
                     "failed" if len(failed_subtasks) > 0 else
                     "running" if len(running_subtasks) > 0 else "pending",
            "completion_percentage": completion_percentage,
            "total_subtasks": total_subtasks,
            "completed_subtasks": len(completed_subtasks),
            "failed_subtasks": len(failed_subtasks),
            "running_subtasks": len(running_subtasks),
            "results": [st.result_data for st in completed_subtasks if st.result_data]
        }
    
    def list_tasks(self):
        """List all submitted tasks and their status"""
        if not self.submitted_tasks:
            print("No tasks submitted yet")
            return
            
        print(f"\nðŸŽ¯ Tasks ({len(self.submitted_tasks)}):")
        print("=" * 50)
        
        for task_id, task in self.submitted_tasks.items():
            status = self.get_task_status(task_id)
            if status:
                print(f"Task: {task.task_type}")
                print(f"  ID: {task_id[:8]}...")
                print(f"  Status: {status['status']}")
                print(f"  Progress: {status['completion_percentage']:.1f}%")
                print(f"  Subtasks: {status['completed_subtasks']}/{status['total_subtasks']}")
                if status['results']:
                    for i, result in enumerate(status['results']):
                        if result:
                            print(f"  Result {i+1}: {result.get('result_type', 'unknown')} - {result.get('duration_seconds', 0):.2f}s")
                print()
    
    def create_sample_tasks(self):
        """Create some sample tasks for testing"""
        tasks = [
            {
                "name": "Matrix Multiplication",
                "type": "matrix_multiply", 
                "data": {"type": "matrix_multiply", "matrix_size": 200, "iterations": 3}
            },
            {
                "name": "Simple ML Training",
                "type": "simple_ml_training",
                "data": {"type": "simple_ml_training", "epochs": 3, "batch_size": 16, "model_size": 500}
            },
            {
                "name": "Data Processing",
                "type": "data_processing", 
                "data": {"type": "data_processing", "data_size": 50000, "operations": ["filter", "map", "sort"]}
            }
        ]
        
        print("ðŸ“‹ Sample tasks available:")
        for i, task in enumerate(tasks):
            print(f"  {i+1}. {task['name']}")
            
        return tasks
    
    def set_as_master(self):
        """Set this device as the master/coordinator"""
        self.is_master_device = True
        self.training_manager.is_master = True
        print(f"ðŸ›ï¸  Device {self.device_id[:8]} is now the MASTER coordinator")
        print("ðŸ“ MacBook will store model weights and coordinate training")
        print("ðŸ“¤ Ready to send training tasks to worker devices")
    
    def start_mnist_training(self, slave_device_ids: List[str], epochs: int = 10, batch_size: int = 32, 
                            learning_rate: float = 0.01, num_samples: int = 5000) -> str:
        """Start MNIST training with specified configuration"""
        if not self.is_master_device:
            print("âŒ Only master device can start distributed training")
            return ""
            
        # Verify slave devices are available (for single device, use self)
        available_slaves = []
        if not slave_device_ids:
            # Single device training
            available_slaves = [self.device_id]
            print(f"ðŸŽ¯ Starting single-device MNIST training on {self.device_id[:8]}...")
        else:
            for device_id in slave_device_ids:
                found = False
                for discovered_device in self.discovered_devices.values():
                    if discovered_device['id'] == device_id:
                        available_slaves.append(device_id)
                        found = True
                        break
                if not found:
                    print(f"âš ï¸  Device {device_id} not found in discovered devices")
            
            if not available_slaves:
                print("âŒ No valid slave devices found")
                return ""
        
        # Create MNIST neural network architecture
        model_config = self.training_manager.create_neural_network(
            input_size=784,     # 28x28 MNIST images
            hidden_sizes=[128, 64],  # Two hidden layers for MNIST
            output_size=10      # 10 digit classes
        )
        
        # Training configuration
        training_config = {
            "epochs": epochs,
            "batch_size": batch_size,
            "learning_rate": learning_rate,
            "num_samples": num_samples
        }
        
        print(f"ðŸ§  MNIST Neural Network Configuration:")
        print(f"   Architecture: 784 â†’ 128 â†’ 64 â†’ 10")
        print(f"   Parameters: {model_config['total_parameters']:,}")
        print(f"   Training samples: {num_samples:,}")
        print(f"   Epochs: {epochs}")
        print(f"   Batch size: {batch_size}")
        print(f"   Learning rate: {learning_rate}")
        
        job_id = self.training_manager.start_distributed_training(
            available_slaves, model_config, training_config
        )
        
        # Start training process in background
        threading.Thread(target=self._run_mnist_training, args=(job_id,), daemon=True).start()
        
        return job_id
    
    def start_distributed_neural_training(self, slave_device_ids: List[str]) -> str:
        """Start distributed neural network training with specified slave devices"""
        # Use MNIST by default
        return self.start_mnist_training(slave_device_ids)
    
    def _run_mnist_training(self, job_id: str):
        """Run the MNIST training process with detailed metrics"""
        try:
            job = self.training_manager.training_jobs[job_id]
            job.status = "training"
            
            print(f"\nðŸƒâ€â™‚ï¸ Starting MNIST training across {len(job.slave_devices)} device(s)")
            print(f"ðŸŽ¯ Target: Train neural network to recognize handwritten digits (0-9)")
            
            # Track training metrics
            epoch_losses = []
            epoch_accuracies = []
            total_training_time = 0
            
            for epoch in range(job.total_epochs):
                epoch_start = time.time()
                print(f"\nðŸ“š Epoch {epoch + 1}/{job.total_epochs}")
                job.current_epoch = epoch
                
                # Distribute batches to slave devices (with single device getting 100% workload)
                device_workloads = {job.slave_devices[0]: 1.0} if len(job.slave_devices) == 1 else None
                batches = self.training_manager.distribute_epoch_batches(job_id, device_workloads)
                print(f"   ðŸ“¦ Created {len(batches)} training batches")
                
                # Process batches - send to workers or execute locally
                gradient_results = []
                batch_count = 0
                
                for batch in batches:
                    batch_count += 1
                    if len(batches) <= 5 or batch_count % max(1, len(batches) // 5) == 0:
                        print(f"   ðŸ”„ Processing batch {batch_count}/{len(batches)} ({len(batch.data)} samples)")
                    
                    # Find which device should process this batch
                    target_device_id = batch.model_weights.get('assigned_device', job.slave_devices[0])
                    
                    if target_device_id == self.device_id:
                        # Process locally (single device mode)
                        result = self.training_manager.process_training_batch(batch)
                        gradient_results.append(result)
                    else:
                        # Send to worker device (MacBook â†’ iPad)
                        target_device = None
                        for device_id, device_info in self.discovered_devices.items():
                            if device_info['id'] == target_device_id:
                                target_device = device_info
                                break
                        
                        if target_device:
                            print(f"   ðŸ“¤ Sending batch to {target_device['name']} ({target_device['address']})")
                            
                            # Send work to iPad
                            result = self.training_service.send_training_batch(
                                target_device['address'], 
                                8090,  # Training service port
                                batch
                            )
                            
                            if result:
                                device_name = result.get('device_name', target_device['name'])
                                used_tinygrad = result.get('used_tinygrad', False)
                                computation_time = result.get('computation_time', 0)
                                
                                print(f"   ðŸ“¥ Received from {device_name}: {'Tinygrad' if used_tinygrad else 'Simulation'} ({computation_time:.2f}s)")
                                
                                if used_tinygrad:
                                    proof = result.get('computation_proof', {})
                                    if 'gradient_norms' in proof:
                                        total_norm = sum(proof['gradient_norms'].values())
                                        print(f"      ðŸ§® Real gradients computed (total norm: {total_norm:.4f})")
                                
                                gradient_results.append(result)
                            else:
                                print(f"   âŒ Failed to get result from {target_device['name']}")
                        else:
                            # Fallback to local processing
                            print(f"   âš ï¸  Device {target_device_id[:8]} not available, processing locally")
                            result = self.training_manager.process_training_batch(batch)
                            gradient_results.append(result)
                    
                    # Small delay between batches
                    time.sleep(0.1)
                
                # Aggregate gradients from all devices
                aggregated = self.training_manager.aggregate_gradients(job_id, gradient_results)
                
                if aggregated:
                    avg_loss = aggregated["average_loss"]
                    avg_accuracy = aggregated["average_accuracy"]
                    total_samples = aggregated["total_samples"]
                    computation_time = aggregated["total_computation_time"]
                    
                    epoch_losses.append(avg_loss)
                    epoch_accuracies.append(avg_accuracy)
                    
                    print(f"   ðŸ“Š Loss: {avg_loss:.4f} | Accuracy: {avg_accuracy:.3f} ({avg_accuracy*100:.1f}%) | Samples: {total_samples}")
                    print(f"   â±ï¸  Computation: {computation_time:.2f}s | Learning rate: {job.training_config['learning_rate']:.3f}")
                    
                    # Update model parameters
                    self.training_manager.update_model_parameters(
                        job_id, 
                        aggregated["aggregated_gradients"], 
                        job.training_config["learning_rate"]
                    )
                    
                    # Show progress indicators
                    if epoch > 0:
                        loss_change = epoch_losses[-1] - epoch_losses[-2]
                        acc_change = epoch_accuracies[-1] - epoch_accuracies[-2]
                        loss_trend = "ðŸ“‰" if loss_change < 0 else "ðŸ“ˆ" if loss_change > 0 else "âž¡ï¸"
                        acc_trend = "ðŸ“ˆ" if acc_change > 0 else "ðŸ“‰" if acc_change < 0 else "âž¡ï¸"
                        print(f"   ðŸ“ˆ Trends: Loss {loss_trend} ({loss_change:+.4f}) | Accuracy {acc_trend} ({acc_change:+.3f})")
                    
                    print(f"   âœ… Model parameters updated")
                
                epoch_time = time.time() - epoch_start
                total_training_time += epoch_time
                print(f"   ðŸ• Epoch completed in {epoch_time:.1f}s")
                
                # Adaptive learning rate (simple decay)
                if epoch > 0 and epoch % 3 == 0:
                    job.training_config["learning_rate"] *= 0.9
                    print(f"   ðŸ“‰ Learning rate reduced to {job.training_config['learning_rate']:.4f}")
            
            job.status = "completed"
            
            # Save model to MacBook (if master)
            if self.is_master_device:
                model_path = self.save_trained_model(job_id, job, epoch_losses[-1], epoch_accuracies[-1])
                print(f"ðŸ’¾ Model saved to: {model_path}")
            
            # Training summary
            print(f"\nðŸŽ‰ MNIST Training Completed!")
            print(f"ðŸ“Š Final Results:")
            print(f"   Final Loss: {epoch_losses[-1]:.4f}")
            print(f"   Final Accuracy: {epoch_accuracies[-1]:.3f} ({epoch_accuracies[-1]*100:.1f}%)")
            print(f"   Total Training Time: {total_training_time:.1f}s")
            print(f"   Average Time per Epoch: {total_training_time/job.total_epochs:.1f}s")
            print(f"   Model Parameters: {job.model_config['total_parameters']:,}")
            
            # Estimate model performance
            if epoch_accuracies[-1] > 0.9:
                print(f"ðŸ† Excellent! Your model achieved >90% accuracy!")
            elif epoch_accuracies[-1] > 0.8:
                print(f"ðŸ‘ Good performance! Model achieved >80% accuracy")
            elif epoch_accuracies[-1] > 0.6:
                print(f"ðŸ“š Learning! Model achieved >60% accuracy")
            else:
                print(f"ðŸ”„ Model is still learning. Try more epochs or adjust hyperparameters.")
            
        except Exception as e:
            print(f"âŒ Error in MNIST training: {e}")
            if job_id in self.training_manager.training_jobs:
                self.training_manager.training_jobs[job_id].status = "failed"
    
    def _run_distributed_training(self, job_id: str):
        """Run the distributed training process (Master only)"""
        # Use the MNIST training for now
        self._run_mnist_training(job_id)
    
    def get_training_jobs(self):
        """List all training jobs"""
        if not self.training_manager.training_jobs:
            print("No training jobs found")
            return
            
        print(f"\nðŸŽ¯ Training Jobs ({len(self.training_manager.training_jobs)}):")
        print("=" * 60)
        
        for job_id, job in self.training_manager.training_jobs.items():
            status = self.training_manager.get_training_status(job_id)
            if status:
                print(f"Job: {job_id[:8]}...")
                print(f"  Status: {status['status']}")
                print(f"  Progress: {status['progress']:.1f}% ({status['current_epoch']}/{status['total_epochs']} epochs)")
                print(f"  Model: {status['model_info']['layers']} layers, {status['model_info']['parameters']} parameters")
                print(f"  Workers: {len(status['slave_devices'])} devices")
                print(f"  Master: {status['master_device'][:8]}...")
                print()
    
    def simulate_slave_mode(self):
        """Set this device as a slave worker"""
        self.is_master_device = False
        self.training_manager.is_master = False
    
    def save_trained_model(self, job_id: str, job: DistributedTrainingJob, final_loss: float, final_accuracy: float) -> str:
        """Save trained model to MacBook storage"""
        import os
        import json
        
        # Create models directory
        models_dir = os.path.expanduser("~/discompute_models")
        os.makedirs(models_dir, exist_ok=True)
        
        # Create filename with timestamp
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        model_name = f"mnist_model_{timestamp}_{job_id[:8]}"
        model_path = os.path.join(models_dir, f"{model_name}.json")
        
        # Prepare model data
        model_data = {
            "job_id": job_id,
            "model_type": "MNIST_Classifier",
            "architecture": job.model_config,
            "trained_parameters": job.model_parameters,
            "training_config": job.training_config,
            "final_metrics": {
                "loss": final_loss,
                "accuracy": final_accuracy,
                "epochs_trained": job.total_epochs
            },
            "training_info": {
                "device_count": len(job.slave_devices),
                "master_device": self.device_id,
                "worker_devices": job.slave_devices,
                "training_date": timestamp
            },
            "metadata": {
                "framework": "discompute",
                "version": "1.0",
                "total_parameters": job.model_config["total_parameters"]
            }
        }
        
        # Save model
        try:
            with open(model_path, 'w') as f:
                json.dump(model_data, f, indent=2)
            
            print(f"ðŸ“ Model details:")
            print(f"   File: {model_name}.json")
            print(f"   Location: {models_dir}")
            print(f"   Size: {os.path.getsize(model_path) / 1024:.1f} KB")
            print(f"   Parameters: {job.model_config['total_parameters']:,}")
            
            return model_path
            
        except Exception as e:
            print(f"âŒ Failed to save model: {e}")
            return ""
    
    def list_saved_models(self):
        """List all saved models on MacBook"""
        import os
        import json
        
        models_dir = os.path.expanduser("~/discompute_models")
        if not os.path.exists(models_dir):
            print("No saved models found")
            return
        
        model_files = [f for f in os.listdir(models_dir) if f.endswith('.json')]
        
        if not model_files:
            print("No saved models found")
            return
        
        print(f"\nðŸ’¾ Saved Models ({len(model_files)}):")
        print("=" * 60)
        
        for model_file in sorted(model_files, reverse=True):  # Most recent first
            try:
                model_path = os.path.join(models_dir, model_file)
                with open(model_path, 'r') as f:
                    model_data = json.load(f)
                
                metrics = model_data.get("final_metrics", {})
                info = model_data.get("training_info", {})
                
                print(f"Model: {model_file}")
                print(f"  Type: {model_data.get('model_type', 'Unknown')}")
                print(f"  Accuracy: {metrics.get('accuracy', 0):.3f} ({metrics.get('accuracy', 0)*100:.1f}%)")
                print(f"  Loss: {metrics.get('loss', 0):.4f}")
                print(f"  Epochs: {metrics.get('epochs_trained', 0)}")
                print(f"  Devices: {info.get('device_count', 1)}")
                print(f"  Date: {info.get('training_date', 'Unknown')}")
                print(f"  Size: {os.path.getsize(model_path) / 1024:.1f} KB")
                print()
                
            except Exception as e:
                print(f"Error reading {model_file}: {e}")
                print()
    
    def start_slave_mode(self):
        """Set this device as a slave worker"""
        self.is_master_device = False
        self.training_manager.is_master = False
        
        # Start training service to receive work from master
        port = self.training_service.start_server(port=8090)
        if port:
            print(f"ðŸ¤– Device {self.device_id[:8]} is now in SLAVE mode")
            print(f"ðŸ”Œ Training service listening on port {port}")
            print("âš¡ iPad ready to receive compute work from MacBook")
            print("ðŸ“¥ Waiting for training batches from master...")
        else:
            print("âŒ Failed to start slave training service")
    
    def install_dependencies(self):
        """Install all required dependencies: numpy, tinygrad, and grpc"""
        import subprocess
        import sys
        
        print("ðŸ“¦ Installing required dependencies for distributed AI training...")
        print("ðŸ”„ This may take several minutes on iPad...")
        
        packages = [
            ('numpy', 'Numerical computing'),
            ('tinygrad', 'Real neural network training'),
            ('grpcio', 'Distributed communication'),
            ('protobuf', 'Message serialization')
        ]
        
        for package_name, description in packages:
            try:
                print(f"   Installing {package_name} ({description})...")
                
                # Try different pip commands that work on iOS
                pip_commands = [
                    [sys.executable, '-m', 'pip', 'install', package_name],
                    ['pip3', 'install', package_name],
                    ['pip', 'install', package_name],
                    ['python3', '-m', 'pip', 'install', package_name]
                ]
                
                success = False
                for cmd in pip_commands:
                    try:
                        print(f"      Trying: {' '.join(cmd)}")
                        result = subprocess.run(
                            cmd, 
                            capture_output=True, 
                            text=True, 
                            timeout=600  # 10 minute timeout for gRPC
                        )
                        
                        if result.returncode == 0:
                            print(f"   âœ… {package_name} installed successfully")
                            success = True
                            break
                        else:
                            if result.stderr and 'permission' not in result.stderr.lower():
                                print(f"      âš ï¸  Error: {result.stderr[:100]}...")
                                
                    except subprocess.TimeoutExpired:
                        print(f"   â° Installation timeout for {package_name} (this is normal for gRPC)")
                        continue
                    except FileNotFoundError:
                        continue  # Try next command
                    except Exception as e:
                        print(f"   âŒ Error with command {' '.join(cmd)}: {e}")
                        continue
                
                if not success:
                    print(f"   âŒ Failed to install {package_name}")
                    print(f"   ðŸ“ Try manually: pip3 install {package_name}")
                else:
                    print(f"   ðŸŽ‰ {package_name} ready!")
                    
            except Exception as e:
                print(f"   âŒ Error installing {package_name}: {e}")
        
        print("\nðŸ”„ Installation complete. Restart the client to enable all features:")
        print("   python3 discompute_mobile.py")
        print("\nYou should then see:")
        print("   ðŸ§  Tinygrad available - real neural network training enabled")
        print("   âœ… gRPC available - real distributed training enabled")
    
    def check_dependencies(self):
        """Check if all required dependencies are properly installed"""
        print("ðŸ” Checking dependencies...")
        
        all_good = True
        
        # Check NumPy
        try:
            import numpy as np
            print("âœ… NumPy is installed and working")
            print(f"   Version: {np.__version__}")
            test_array = np.array([1.0, 2.0, 3.0])
            print(f"   Test array: {test_array}")
        except ImportError:
            print("âŒ NumPy not available")
            all_good = False
        except Exception as e:
            print(f"âš ï¸  NumPy installed but not working: {e}")
            all_good = False
        
        # Check Tinygrad
        try:
            import tinygrad
            from tinygrad import Tensor, nn
            print("âœ… Tinygrad is installed and working")
            print(f"   Version: {getattr(tinygrad, '__version__', 'unknown')}")
            
            # Test basic functionality
            test_tensor = Tensor([1.0, 2.0, 3.0])
            print(f"   Test tensor: {test_tensor.numpy()}")
        except ImportError:
            print("âŒ Tinygrad not available")
            all_good = False
        except Exception as e:
            print(f"âš ï¸  Tinygrad installed but not working: {e}")
            all_good = False
        
        # Check gRPC
        try:
            import grpc
            import concurrent.futures
            print("âœ… gRPC is installed and working")
            print(f"   Version: {grpc.__version__}")
            
            # Test basic functionality
            print("   Testing gRPC server creation...")
            server = grpc.server(concurrent.futures.ThreadPoolExecutor(max_workers=1))
            print("   âœ… gRPC server test passed")
        except ImportError:
            print("âŒ gRPC not available")
            all_good = False
        except Exception as e:
            print(f"âš ï¸  gRPC installed but not working: {e}")
            all_good = False
        
        # Check protobuf
        try:
            import google.protobuf
            print("âœ… Protobuf is installed and working")
            print(f"   Version: {google.protobuf.__version__}")
        except ImportError:
            print("âŒ Protobuf not available")
            all_good = False
        except Exception as e:
            print(f"âš ï¸  Protobuf installed but not working: {e}")
            all_good = False
        
        print(f"\n{'ðŸŽ‰ All dependencies ready!' if all_good else 'âš ï¸  Some dependencies missing'}")
        
        if all_good:
            print("ðŸš€ Ready for distributed AI training with real neural networks!")
        else:
            print("ðŸ“¦ Run 'install' command to install missing dependencies")
        
        return all_good
    
    def enable_tinygrad_mode(self):
        """Enable Tinygrad mode for real neural network training"""
        if not HAS_TINYGRAD:
            print("âŒ Tinygrad not installed. Run 'install' first.")
            return False
        
        self.use_tinygrad = True
        print("âœ… Tinygrad mode enabled")
        print("ðŸ§  Real neural network training will be used")
        print("âš ï¸  Note: This may be unstable on some iOS devices")
        return True
    
    def disable_tinygrad_mode(self):
        """Disable Tinygrad mode (use simulation)"""
        self.use_tinygrad = False
        print("ðŸ”„ Tinygrad mode disabled")
        print("ðŸŽ­ Using simulation mode for stability")
        return True
    
    def get_stats(self):
        """Get service statistics"""
        uptime = time.time() - self.start_time
        
        # Task statistics
        total_tasks = len(self.submitted_tasks)
        completed_tasks = 0
        running_tasks = 0
        failed_tasks = 0
        
        for task_id in self.submitted_tasks:
            status = self.get_task_status(task_id)
            if status:
                if status['status'] == 'completed':
                    completed_tasks += 1
                elif status['status'] == 'running':
                    running_tasks += 1
                elif status['status'] == 'failed':
                    failed_tasks += 1
        
        return {
            'running': self.running,
            'device_id': self.device_id,
            'discovered_devices': len(self.discovered_devices),
            'device_type': self.device_capabilities['type'],
            'chip': self.device_capabilities['chip'],
            'uptime_seconds': round(uptime, 1),
            'total_tasks': total_tasks,
            'completed_tasks': completed_tasks,
            'running_tasks': running_tasks,
            'failed_tasks': failed_tasks,
            'active_executor_tasks': len(self.task_executor.running_tasks),
            'is_master_device': self.is_master_device,
            'training_jobs': len(self.training_manager.training_jobs)
        }

def main():
    """Main function for interactive use"""
    print("ðŸŽ Discompute iOS Client")
    print("Compatible with Pyto, a-Shell, and other Python iOS apps")
    print()
    
    # Check for debug flag
    debug = len(sys.argv) > 1 and sys.argv[1] == '--debug'
    
    # Create client
    client = DiscomputeMobile(debug=debug)
    
    try:
        # Start discovery
        client.start_discovery()
        
        print("\nCommands:")
        print("  'list' - Show discovered devices")
        print("  'info' - Show this device info") 
        print("  'stats' - Show statistics")
        print("  'debug' - Show network diagnostics")
        print("  'test' - Test listener by sending to localhost")
        print("  'tasks' - Show submitted tasks")
        print("  'samples' - Show sample AI tasks")
        print("  'submit <task_type>' - Submit a task (e.g., 'submit matrix')")
        print("  'master' - Set this device as master coordinator")
        print("  'slave' - Set this device as slave worker")
        print("  'mnist' - Start MNIST digit recognition training")
        print("  'train <device_ids>' - Start distributed neural training")
        print("  'jobs' - Show distributed training jobs")
        print("  'models' - List saved models (MacBook only)")
        print("  'install' - Install all dependencies (numpy, tinygrad, grpc)")
        print("  'check' - Check if all dependencies are installed and working")
        print("  'enable' - Enable Tinygrad mode for real neural networks")
        print("  'disable' - Disable Tinygrad mode (use simulation)")
        print("  'testnn' - Test real Tinygrad neural network training")
        print("  'send <device_id> <message>' - Send test message")
        print("  'quit' - Exit")
        print()
        
        while True:
            try:
                cmd = input("discompute> ").strip().lower()
                
                if cmd == 'quit' or cmd == 'exit':
                    break
                elif cmd == 'list':
                    client.list_devices()
                elif cmd == 'info':
                    caps = client.device_capabilities
                    print(f"Device: {caps['model']} ({caps['type']})")
                    print(f"Chip: {caps['chip']}")
                    print(f"Memory: {caps['memory']} MB")
                    print(f"Compute: {caps['flops']['fp32']:.2f} TFLOPS")
                elif cmd == 'stats':
                    stats = client.get_stats()
                    for key, value in stats.items():
                        print(f"{key}: {value}")
                elif cmd == 'debug':
                    client.print_network_info()
                elif cmd == 'test':
                    client.test_listener()
                elif cmd == 'tasks':
                    client.list_tasks()
                elif cmd == 'samples':
                    client.create_sample_tasks()
                elif cmd.startswith('submit '):
                    task_type = cmd.split(' ', 1)[1] if len(cmd.split(' ')) > 1 else ""
                    samples = client.create_sample_tasks()
                    
                    if task_type == "matrix" or task_type == "1":
                        task_data = samples[0]["data"]
                        task_id = client.submit_task("matrix_multiply", task_data)
                        print(f"âœ… Submitted matrix multiplication task: {task_id[:8]}...")
                    elif task_type == "training" or task_type == "ml" or task_type == "2":
                        task_data = samples[1]["data"]
                        task_id = client.submit_task("simple_ml_training", task_data)
                        print(f"âœ… Submitted ML training task: {task_id[:8]}...")
                    elif task_type == "data" or task_type == "processing" or task_type == "3":
                        task_data = samples[2]["data"]
                        task_id = client.submit_task("data_processing", task_data)
                        print(f"âœ… Submitted data processing task: {task_id[:8]}...")
                    else:
                        print("Available task types: matrix, training, data (or numbers 1-3)")
                elif cmd == 'master':
                    client.set_as_master()
                elif cmd == 'slave':
                    client.start_slave_mode()
                elif cmd == 'models':
                    client.list_saved_models()
                elif cmd == 'install':
                    client.install_dependencies()
                elif cmd == 'check':
                    client.check_dependencies()
                elif cmd == 'enable':
                    client.enable_tinygrad_mode()
                elif cmd == 'disable':
                    client.disable_tinygrad_mode()
                elif cmd == 'testnn':
                    if HAS_TINYGRAD:
                        print("ðŸ§  Testing real Tinygrad neural network...")
                        test_model = TinygradMNISTModel()
                        if test_model.is_built:
                            loss, acc = test_model.train_steps_official(100)
                            print(f"ðŸŽ‰ Test completed: {acc*100:.2f}% accuracy!")
                        else:
                            print("âŒ Failed to build test model")
                    else:
                        print("âŒ Tinygrad not available. Run 'install' first.")
                elif cmd == 'jobs':
                    client.get_training_jobs()
                elif cmd == 'mnist':
                    if not client.is_master_device:
                        print("âš ï¸  Setting device as master first...")
                        client.set_as_master()
                    
                    print("ðŸŽ¯ Starting MNIST training on this device...")
                    job_id = client.start_mnist_training([], epochs=10, batch_size=32, num_samples=2000)
                    if job_id:
                        print(f"âœ… Started MNIST training job: {job_id[:8]}...")
                        print("ðŸ“Š Watch the training progress above!")
                elif cmd.startswith('train '):
                    device_list = cmd.split(' ', 1)[1] if len(cmd.split(' ')) > 1 else ""
                    if device_list:
                        # Parse device IDs from command
                        device_ids = [d.strip() for d in device_list.split(',')]
                        
                        # Try to match partial device IDs with discovered devices
                        matched_devices = []
                        for partial_id in device_ids:
                            for device_id, device_info in client.discovered_devices.items():
                                if device_info['id'].startswith(partial_id) or partial_id in device_info['id']:
                                    matched_devices.append(device_info['id'])
                                    break
                        
                        if matched_devices:
                            print(f"Starting distributed training with devices: {[d[:8] + '...' for d in matched_devices]}")
                            job_id = client.start_distributed_neural_training(matched_devices)
                            if job_id:
                                print(f"âœ… Started training job: {job_id[:8]}...")
                        else:
                            print("âŒ No matching devices found")
                            print("Available devices:")
                            for device_id, device_info in client.discovered_devices.items():
                                print(f"  {device_info['id'][:8]}... ({device_info['name']})")
                    else:
                        print("Usage: train <device_id1>,<device_id2>,...")
                        print("Example: train abc123,def456")
                        if client.discovered_devices:
                            print("Available devices:")
                            for device_id, device_info in client.discovered_devices.items():
                                print(f"  {device_info['id'][:8]}... ({device_info['name']})")
                elif cmd.startswith('send '):
                    parts = cmd.split(' ', 2)
                    if len(parts) >= 3:
                        client.send_test_message(parts[1], parts[2])
                    else:
                        print("Usage: send <device_id> <message>")
                elif cmd == 'help':
                    print("Available commands: list, info, stats, debug, test, tasks, samples, submit, master, slave, mnist, train, jobs, models, install, check, enable, disable, testnn, send, quit")
                elif cmd == '':
                    continue
                else:
                    print(f"Unknown command: {cmd}")
                    
            except KeyboardInterrupt:
                break
            except EOFError:
                break
                
    finally:
        client.stop_discovery()
        print("ðŸ‘‹ Goodbye!")

if __name__ == "__main__":
    main()
